/**
 * AI Agent with modular tools, LLM abstraction, and history management
 */

import * as readline from "readline/promises";
import { writeFile, mkdir } from "fs/promises";
import path from "path";
import { existsSync } from "fs";
import {
  LLMProvider,
  LLMResponse,
  ContentBlock,
  ToolUse,
  StreamEvent,
} from "./llm";
import { AnthropicProvider } from "./llm/anthropic";
import { ConversationHistory } from "./history";
import { getToolDefinitions, executeTool, getToolNames } from "./tools";

// å®šæ•°
const MODEL_NAME = "claude-sonnet-4-5-20250929";
const MAX_TOKENS = 4096;
const MAX_ITERATIONS = 25;
const SEPARATOR_LENGTH = 60;
const WORKSPACE_DIR = path.join(process.cwd(), "workspace");
const SAMPLE_FILE_NAME = "example.txt";
const SAMPLE_FILE_CONTENT = "Hello, this is an example file!\nYou can read and modify this file.";
const EXIT_COMMANDS = ["exit", "quit", ""];
const ATTEMPT_COMPLETION_TOOL_NAME = "attempt_completion";

interface AttemptCompletionInput {
  result: string;
}

interface ProcessResult {
  shouldContinue: boolean;
  isCompleted: boolean;
}

// LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’ä½œæˆ
function createLLMProvider(): LLMProvider {
  return new AnthropicProvider({
    apiKey: process.env.ANTHROPIC_API_KEY ?? "",
    model: MODEL_NAME,
    maxTokens: MAX_TOKENS,
  });
}

/**
 * ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’å–å¾—
 */
async function getUserInput(prompt: string = "å…¥åŠ›"): Promise<string> {
  const rl = readline.createInterface({
    input: process.stdin,
    output: process.stdout,
  });

  const answer = await rl.question(`\n${prompt}: `);
  rl.close();
  return answer;
}

/**
 * ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚¤ãƒ™ãƒ³ãƒˆã‚’å‡¦ç†
 */
function handleStreamEvent(event: StreamEvent): void {
  switch (event.type) {
    case "text":
      process.stdout.write(event.text ?? "");
      break;
    case "tool_use_start":
      console.log(`\nğŸ”§ ãƒ„ãƒ¼ãƒ«ä½¿ç”¨: ${event.toolName}`);
      break;
    case "done":
      console.log();
      break;
  }
}

/**
 * LLMã‚’å‘¼ã³å‡ºã—
 */
async function callLLM(
  provider: LLMProvider,
  history: ConversationHistory
): Promise<LLMResponse> {
  console.log("\nğŸ¤– LLMã®å¿œç­”:");

  const tools = getToolDefinitions();
  const messages = history.toBaseMessages();

  return provider.call(messages, tools, handleStreamEvent);
}

/**
 * ãƒ„ãƒ¼ãƒ«ä½¿ç”¨ã‚’å‡¦ç†
 */
async function processToolUse(
  toolUse: ToolUse,
  history: ConversationHistory
): Promise<{ isCompleted: boolean }> {
  if (toolUse.name === ATTEMPT_COMPLETION_TOOL_NAME) {
    const input = toolUse.input as unknown as AttemptCompletionInput;
    console.log("\nâœ… ã‚¿ã‚¹ã‚¯å®Œäº†:", input.result);
    history.addTaskCompletion(input.result);
    return { isCompleted: true };
  }

  const result = await executeTool(toolUse.name, toolUse.input);
  history.addToolResult(toolUse.name, toolUse.id, result);
  return { isCompleted: false };
}

/**
 * ãƒ„ãƒ¼ãƒ«ä½¿ç”¨ãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡º
 */
function extractToolUses(content: ContentBlock[]): ToolUse[] {
  return content
    .filter((block): block is ContentBlock & { type: "tool_use" } => block.type === "tool_use")
    .map((block) => block.toolUse);
}

/**
 * LLMã®å¿œç­”ã‚’å‡¦ç†
 */
async function processResponse(
  response: LLMResponse,
  history: ConversationHistory
): Promise<ProcessResult> {
  // ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¿œç­”ã‚’å±¥æ­´ã«è¿½åŠ 
  history.addAssistantMessage(response.content);

  if (response.stopReason === "end_turn") {
    return { shouldContinue: false, isCompleted: false };
  }

  const toolUses = extractToolUses(response.content);

  if (toolUses.length === 0) {
    return { shouldContinue: true, isCompleted: false };
  }

  // ãƒ„ãƒ¼ãƒ«çµæœã‚’å‡¦ç†
  const results = await Promise.all(
    toolUses.map((toolUse) => processToolUse(toolUse, history))
  );
  const hasCompletion = results.some((r) => r.isCompleted);

  return {
    shouldContinue: !hasCompletion,
    isCompleted: hasCompletion,
  };
}

/**
 * ä¼šè©±ãƒ«ãƒ¼ãƒ—ã‚’å®Ÿè¡Œï¼ˆå†å¸°çš„ï¼‰
 */
async function runConversationLoop(
  provider: LLMProvider,
  history: ConversationHistory,
  iterationCount: number
): Promise<void> {
  if (iterationCount >= MAX_ITERATIONS) {
    console.log("\nâš ï¸ æœ€å¤§ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°ã«é”ã—ã¾ã—ãŸ");
    return;
  }

  const response = await callLLM(provider, history);
  const { shouldContinue } = await processResponse(response, history);

  if (shouldContinue) {
    await runConversationLoop(provider, history, iterationCount + 1);
  }
}

/**
 * çµ‚äº†ã‚³ãƒãƒ³ãƒ‰ã‹ã©ã†ã‹ã‚’åˆ¤å®š
 */
function isExitCommand(input: string): boolean {
  const normalizedInput = input.trim().toLowerCase();
  return EXIT_COMMANDS.includes(normalizedInput);
}

/**
 * ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹åˆæœŸåŒ–
 */
async function initializeWorkspace(): Promise<void> {
  if (existsSync(WORKSPACE_DIR)) {
    return;
  }

  await mkdir(WORKSPACE_DIR, { recursive: true });
  console.log(`ğŸ“ ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ã‚’ä½œæˆã—ã¾ã—ãŸ: ${WORKSPACE_DIR}`);

  await writeFile(
    path.join(WORKSPACE_DIR, SAMPLE_FILE_NAME),
    SAMPLE_FILE_CONTENT,
    "utf-8"
  );
  console.log(`ğŸ“„ ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ${SAMPLE_FILE_NAME}ï¼‰ã‚’ä½œæˆã—ã¾ã—ãŸ`);
}

/**
 * ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¡¨ç¤º
 */
function displayHeader(providerName: string): void {
  const separator = "=".repeat(SEPARATOR_LENGTH);
  console.log(separator);
  console.log(`AI Agent (${providerName})`);
  console.log(separator);
  console.log("\nåˆ©ç”¨å¯èƒ½ãªãƒ„ãƒ¼ãƒ«:");
  getToolNames().forEach((name) => {
    console.log(`  â€¢ ${name}`);
  });
  console.log("\nçµ‚äº†ã™ã‚‹ã«ã¯ 'exit'ã€'quit'ã€ã¾ãŸã¯ Ctrl+C");
}

/**
 * ãƒ•ãƒƒã‚¿ãƒ¼ã‚’è¡¨ç¤º
 */
function displayFooter(): void {
  const separator = "=".repeat(SEPARATOR_LENGTH);
  console.log("\n" + separator);
  console.log("ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†");
  console.log(separator);
}

/**
 * ãƒ¡ã‚¤ãƒ³ã®ä¼šè©±ãƒ«ãƒ¼ãƒ—
 */
async function mainLoop(
  provider: LLMProvider,
  history: ConversationHistory
): Promise<void> {
  const input = await getUserInput();

  if (isExitCommand(input)) {
    console.log("\nğŸ‘‹ çµ‚äº†ã—ã¾ã™");
    return;
  }

  history.addUserMessage(input);

  const initialIterationCount = 0;
  await runConversationLoop(provider, history, initialIterationCount);
  await mainLoop(provider, history);
}

/**
 * Ctrl+C ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’è¨­å®š
 */
function setupSignalHandlers(): void {
  process.on("SIGINT", () => {
    console.log("\n\nğŸ‘‹ Ctrl+C ã§çµ‚äº†ã—ã¾ã™");
    displayFooter();
    process.exit(0);
  });
}

/**
 * ãƒ¡ã‚¤ãƒ³é–¢æ•°
 */
async function main(): Promise<void> {
  setupSignalHandlers();

  const provider = createLLMProvider();
  const history = new ConversationHistory();

  displayHeader(provider.name);

  try {
    await initializeWorkspace();
    await mainLoop(provider, history);
    displayFooter();
  } catch (error) {
    console.error("\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:", error);
    if (error instanceof Error) {
      console.error(error.message);
    }
  }
}

main();
